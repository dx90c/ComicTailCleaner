# ======================================================================
# æª”æ¡ˆï¼šplugins/manga_deduplication/processor.py
# ç›®çš„ï¼šå¯¦ç¾ç›¸ä¼¼å·å®—æŸ¥æ‰¾å™¨ï¼Œä¸¦å‘¼å«æ ¸å¿ƒå¼•æ“é€²è¡Œæª”æ¡ˆæƒæ
# ç‰ˆæœ¬ï¼š11.1 (ä¿®æ­£ç‰ˆï¼šå¯¦ç¾å“ˆå¸Œè¨ˆç®—èˆ‡å¿«å–å…±äº«)
# ======================================================================

from __future__ import annotations
import os
import imagehash
from collections import defaultdict
from typing import Dict, Any, Tuple, List, Optional
from queue import Queue
from multiprocessing import Pool, cpu_count, set_start_method
import sys

try:
    from tkinter import ttk
except ImportError:
    ttk = None

from plugins.base_plugin import BasePlugin
from utils import log_info, log_error, _norm_key
from processors.scanner import ScannedImageCacheManager
# ç›´æ¥å¾æ ¸å¿ƒå¼•æ“å°å…¥ get_files_to_process å’Œ _natural_sort_key
from core_engine import get_files_to_process, _natural_sort_key

from . import plugin_gui

class MangaDeduplicationPlugin(BasePlugin):
    def __init__(self):
        self.ui_vars = {}; self.pool = None

    def get_id(self) -> str: return "manga_volume_deduplication_smart"
    def get_name(self) -> str: return "ç›¸ä¼¼å·å®—æŸ¥æ‰¾ (å…±äº«å¼•æ“ç‰ˆ)"
    def get_description(self) -> str: return "å‘¼å«æ ¸å¿ƒæƒæå¼•æ“ï¼Œæ¯”å°æ¯å€‹è³‡æ–™å¤¾æœ«å°¾Nå¼µåœ–ç‰‡çš„æŒ‡ç´‹ï¼Œæ‰¾å‡ºç›¸ä¼¼çš„æ¼«ç•«å·å®—ã€‚"

    def get_settings_frame(self, parent_frame: 'ttk.Frame', config: Dict[str, Any]) -> Optional['ttk.Frame']:
        if ttk is None: return None
        frame = plugin_gui.create_settings_frame(parent_frame, config, self.ui_vars)
        plugin_gui.load_settings(config, self.ui_vars)
        return frame

    def save_settings(self, config: Dict[str, Any]) -> Dict[str, Any]:
        return plugin_gui.save_settings(config, self.ui_vars)

    def _process_images_with_cache(self, tasks: List[str], cache_manager: ScannedImageCacheManager, progress_queue: Optional[Queue], control_events: Optional[Dict]) -> Dict:
        from utils import _open_image_from_any_path, _get_file_stat, _norm_key, log_error
        try:
            import imagehash
        except ImportError:
            imagehash = None

        results = {}
        updated = 0
        total = len(tasks)

        if imagehash is None:
            raise RuntimeError("ç¼ºå°‘ imagehash å¥—ä»¶ï¼Œç„¡æ³•è¨ˆç®— pHashã€‚")

        for idx, p in enumerate(tasks, 1):
            if control_events and control_events.get('cancel') and control_events['cancel'].is_set():
                break

            key = _norm_key(p)
            size, ctime, mtime = _get_file_stat(p)
            if mtime is None: # _get_file_stat å›å‚³ (None, None, None) è¡¨ç¤ºæª”æ¡ˆä¸å­˜åœ¨
                continue

            cached = cache_manager.get_data(key)
            
            # å‘½ä¸­æ¢ä»¶ï¼šmtime ä¸è®Šã€ä¸”å·²æœ‰ phash
            if cached and abs(cached.get('mtime', 0.0) - mtime) < 1e-6 and cached.get('phash'):
                results[key] = cached
            else:
                try:
                    with _open_image_from_any_path(p) as img:
                        if img is None:
                            continue
                        ph = str(imagehash.phash(img, hash_size=8)) # 64bit pHash
                        meta = {
                            'phash': ph,
                            'mtime': mtime,
                            'size': size,
                            'ctime': ctime,
                        }
                        cache_manager.update_data(key, meta)
                        results[key] = meta
                        updated += 1
                except Exception as e:
                    log_error(f'[å¤–æ›] å“ˆå¸Œå¤±æ•—: {p}: {e}')

            if progress_queue and (idx % 100 == 0 or idx == total):
                progress_queue.put({'type': 'text', 'text': f'ğŸ” [å¤–æ›] æ­£åœ¨è¨ˆç®—æŒ‡ç´‹ {idx}/{total} (æ›´æ–° {updated})'})

        if updated > 0:
            cache_manager.save_cache()
        return results

    def run(self, config: Dict, progress_queue: Optional[Queue] = None, control_events: Optional[Dict] = None) -> Optional[Tuple[List, Dict, List]]:
        _update_progress = lambda text, value=None: progress_queue.put({'type': 'progress' if value is not None else 'text', 'text': text, 'value': value}) if progress_queue else None
        _is_cancelled = lambda: bool(control_events and control_events.get('cancel') and control_events['cancel'].is_set())
        
        try:
            log_info("[ç›¸ä¼¼å·å®—] æº–å‚™åŸ·è¡Œæƒæ (å…±äº«æ ¸å¿ƒå¼•æ“)...")
            _update_progress("ğŸš€ [ç›¸ä¼¼å·å®—] æ­£åœ¨å‘¼å«æ ¸å¿ƒæƒæå¼•æ“...", 0)

            plugin_scan_config = config.copy()
            plugin_scan_config['extract_count'] = int(config.get('plugin_sample_count', 12))
            plugin_scan_config['enable_extract_count_limit'] = config.get('plugin_enable_sample_limit', True)
            
            # --- ã€v11.1 ä¿®æ­£ã€‘ ---
            # æ²¿ç”¨ä¸»ç¨‹å¼çš„å…±äº«å½±åƒå¿«å–å‘½åï¼ˆèˆ‡æ¨¡å¼ç„¡é—œï¼‰
            main_cache = ScannedImageCacheManager(config['root_scan_folder'])
            
            files_to_process, _ = get_files_to_process(plugin_scan_config, main_cache, progress_queue, control_events)
            
            if _is_cancelled(): 
                if progress_queue: progress_queue.put({'type':'status_update', 'text':'å¤–æ›ä»»å‹™å·²ä¸­æ­¢'})
                return None
            if not files_to_process:
                _update_progress("âœ… [ç›¸ä¼¼å·å®—] æœªæ‰¾åˆ°ä»»ä½•åœ–ç‰‡æª”æ¡ˆã€‚"); return [], {}, []

            file_data = self._process_images_with_cache(files_to_process, main_cache, progress_queue, control_events)
            if file_data is None: return None
            
            files_by_folder = defaultdict(list)
            for f_path in file_data:
                files_by_folder[_norm_key(os.path.dirname(f_path))].append(f_path)
            
            fingerprints = {folder: {file_data.get(_norm_key(p), {}).get('phash') for p in paths} - {None} for folder, paths in files_by_folder.items()}

            _update_progress("ğŸ”„ æ¯”å°æŒ‡ç´‹...", 55)
            MATCH_THRESHOLD = int(config.get("plugin_match_threshold", 8))
            folder_list = sorted(list(fingerprints.keys()))
            found_items = []
            
            if len(folder_list) < 2:
                _update_progress("âœ… [ç›¸ä¼¼å·å®—] è³‡æ–™å¤¾æ•¸é‡ä¸è¶³ï¼Œç„¡éœ€æ¯”å°ã€‚"); return [], {}, []

            total_comps = len(folder_list) * (len(folder_list) - 1) // 2
            comps_done = 0
            for i in range(len(folder_list)):
                if _is_cancelled():
                    if progress_queue: progress_queue.put({'type':'status_update', 'text':'å¤–æ›ä»»å‹™å·²ä¸­æ­¢'})
                    return None
                if i > 0 and i % 50 == 0 and total_comps > 0:
                    progress_percent = 55 + int((comps_done / total_comps) * 40)
                    _update_progress(f"ğŸ”„ [ç›¸ä¼¼å·å®—] æ­£åœ¨æ¯”å°... ({i+1}/{len(folder_list)})", value=progress_percent)
                
                for j in range(i + 1, len(folder_list)):
                    comps_done += 1
                    path1, path2 = folder_list[i], folder_list[j]
                    fp1, fp2 = fingerprints[path1], fingerprints[path2]
                    
                    if not fp1 or not fp2: continue
                    
                    intersection_size = len(fp1.intersection(fp2))
                    min_len = min(len(fp1), len(fp2))
                    
                    if min_len == 0: continue
                    
                    current_threshold = MATCH_THRESHOLD
                    limit = config.get('plugin_enable_sample_limit', True)
                    count = int(config.get('plugin_sample_count', 12))
                    if limit and count > 0 and min_len < count:
                        current_threshold = min(MATCH_THRESHOLD, max(1, int(MATCH_THRESHOLD * (min_len / count))))
                    
                    if intersection_size >= current_threshold:
                        found_items.append((min(path1, path2), max(path1, path2), f"{intersection_size}/{min_len} é å…§å®¹é‡åˆ"))
            
            _update_progress("âœ… æ•´ç†çµæœ...", 95)
            gui_file_data = {}
            involved_paths = {p for item in found_items for p in item[:2]}
            for path in involved_paths:
                image_files_for_preview = files_by_folder.get(_norm_key(path))
                if image_files_for_preview:
                    gui_file_data[path] = {'display_path': sorted(image_files_for_preview, key=_natural_sort_key)[0]}
                else: 
                    gui_file_data[path] = {}

            log_info(f"[ç›¸ä¼¼å·å®—] æƒæå®Œæˆï¼Œæ‰¾åˆ° {len(found_items)} çµ„ç›¸ä¼¼é …ç›®ã€‚")
            _update_progress("âœ… [ç›¸ä¼¼å·å®—] å®Œæˆï¼", value=100)
            return found_items, gui_file_data, []
        except Exception as e:
            log_error(f"[å¤–æ›] åŸ·è¡ŒæœŸé–“ç™¼ç”Ÿåš´é‡éŒ¯èª¤: {e}", include_traceback=True)
            if progress_queue: progress_queue.put({'type':'text', 'text': f"âŒ éŒ¯èª¤: {e}"})
            return [], {}, [("å¤–æ›éŒ¯èª¤", str(e))]
        finally:
            if self.pool: 
                self.pool.close()
                self.pool.join()
                self.pool = None
                log_info("[å¤–æ›å¼•æ“] å¤šé€²ç¨‹æ± å·²é—œé–‰ã€‚")